from unstructured.partition.pdf import partition_pdf
from fastapi import HTTPException
import logging, traceback
from .user import GUIDELINES
from .azure_model import azure_openai
from langchain.chains import LLMChain
from .prompts import GUILDELINES_PROMPT


def extract_guidlines(file,file_type) -> str:
    """
    Extracts and returns text from a PDF file.
    This function is designed to process a PDF file and extract its textual content.

    Parameters:
    - file (file-like object): The PDF file from which text needs to be extracted.
    - file_type (str): The type of the file, expected to be 'pdf' for this function.

    Returns:
    - str: A string containing the extracted text from the PDF file.
    """
    extracted_text = []
    if file and file_type=="pdf":
        documents = partition_pdf(file,strategy="ocr_only",infer_table_structure=True)

        for document in documents:
            extracted_text.append(document.text)

        return " ".join(extracted_text) 
    else:
        error_msg = "File Type is not valid "
        logging.error(f"Error: {error_msg} trace_back:{traceback.format_exc()}")
        raise HTTPException(status_code=422,detail=error_msg)
    



def guidelines_chain(query,gpt_response) -> str:
    """
    Processes a query and a GPT response through a set of guidelines to refine the response.

    This function takes a user query and a response generated by GPT,and processes it through a series of guidelines. 
    The function attempts to refine the GPT response based on these guidelines.

    Parameters:
    - query (str): The original query made by the user.
    - gpt_response (str): The initial response generated by the GPT model.

    Returns:
    - str: The refined response after processing through the guidelines, or the original GPT response 
        if the guidelines processing fails or is not applicable.
    """
    
    try:
        guidelines = GUIDELINES.get("guidelines")
        if guidelines is not None:

            max_retries = 7
            retries = 0

            while retries<max_retries:

                try:
                    guideline_chian = LLMChain(llm=azure_openai,prompt=GUILDELINES_PROMPT,output_key="refactored_response")
                    input_variables = {"user_query":query,"llm_response":gpt_response,"admin_instructions":guidelines}
                    response = guideline_chian.run(input_variables)
                    if response is not None:
                        return response
                except:
                    response = None
                
                retries += 1

        return gpt_response
    except Exception as e:
        error_msg =" Error while Generating Guidlines Chain:"
        logging.error(f"{error_msg}{e} trace_back:{traceback.format_exc()}")
        raise Exception (f"{error_msg} {e}")

    
    